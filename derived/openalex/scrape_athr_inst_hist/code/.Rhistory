associated<-append(associated, list(c("")))
associated_country<-append(associated_country, list(c("")))
associated_type<-append(associated_type, list(c("")))
associated_rel<-append(associated_rel, list(c("")))
}
}
associated_id <- associated_id %>% data.frame %>% t()
associated <- associated %>% data.frame %>% t()
associated_country <- associated_country %>% data.frame %>% t()
associated_type <- associated_type %>% data.frame %>% t()
associated_rel <- associated_rel %>% data.frame %>% t()
inst_chars <- cbind(inst_geo, associated, associated_id, associated_country, associated_type, associated_rel) %>%
group_by(inst_id, which_inst) %>%
mutate(which_assoc = 1:n(),
inst_id = str_replace(inst_id, "https://openalex.org/",""),
associated_id = str_replace(associated_id, "https://openalex.org/",""))
write_csv(inst_chars, paste0("../output/inst_geo_chars", as.character(q), ".csv"))
}
library(openalexR)
library(dplyr)
library(ggplot2)
library(here)
library(haven)
library(stringr)
library(purrr)
library(tidyverse)
set.seed(8975)
################################### MAIN ###################################
insts <- read_dta('../output/list_of_insts.dta')
nr <- nrow(insts)
split_insts <- split(insts, rep(1:ceiling(nr/5000), each = 5000, length.out=nr))
num_file <- length(split_insts)
for (q in 1:1) {
insts <- oa_fetch(
entity = "institutions",
id  = split_insts[[q]] %>%  mutate(inst_id = as.character(inst_id)) %>% pull(inst_id),
verbose = TRUE,
output = "list"
)
N_insts <- length(insts)
inst_geo <- lapply(1:N_insts, function(i) {
if (length(insts[[i]][["id"]])!=0) {
inst_id <- insts[[i]][["id"]] %>% data.frame
}
if (length(insts[[i]][["display_name"]])!=0) {
inst <-  insts[[i]][["display_name"]] %>% data.frame
}
else {
inst <- c("")%>% data.frame
}
if (length(insts[[i]][["country_code"]])!=0) {
country_code <- insts[[i]][["country_code"]] %>% data.frame
}
else {
country_code <- c("")%>% data.frame
}
if (length(insts[[i]][["type"]])!=0) {
type <- insts[[i]][["type"]] %>% data.frame
}
else {
type <- c("")%>% data.frame
}
if (length(insts[[i]][["geo"]][["city"]])!=0) {
city <- insts[[i]][["geo"]][["city"]]%>% data.frame
}
else {
city <- c("")%>% data.frame
}
if (length(insts[[i]][["geo"]][["country"]])!=0) {
country <- insts[[i]][["geo"]][["country"]]%>% data.frame
}
else {
country <- c("")%>% data.frame
}
if (length(insts[[i]][["geo"]][["region"]])!=0) {
region <- insts[[i]][["geo"]][["region"]]%>% data.frame
}
else {
region <- c("")%>% data.frame
}
num_assocs <-length(insts[[i]][["associated_institutions"]])%>% data.frame
cbind(inst_id, inst, country_code, country, city, region, type, num_assocs)
}) %>% bind_rows()
colnames(inst_geo) <- c("inst_id","inst", "country_code", "country", "city", "region", "type", "num_assocs")
inst_geo <- inst_geo %>%
mutate(which_inst = 1:n(),
num_assocs = replace(num_assocs, num_assocs == 0, 1)) %>%
uncount(num_assocs)
associated_id <- list()
associated <- list()
associated_country <- list()
associated_type <- list()
associated_rel <- list()
for(i in 1:N_insts) {
N_assocs <- length(insts[[i]][["associated_institutions"]])
if (N_assocs !=0) {
for(j in 1:N_assocs) {
if(length(insts[[i]][["associated_institutions"]][[j]][["id"]])!=0) {
associated_id<-append(associated_id, insts[[i]][["associated_institutions"]][[j]][["id"]])
}
else {
associated_id<-append(associated_id, list(c("")))
}
if(length(insts[[i]][["associated_institutions"]][[j]][["display_name"]])!=0) {
associated<-append(associated, insts[[i]][["associated_institutions"]][[j]][["display_name"]])
}
else {
associated<-append(associated, list(c("")))
}
if(length(insts[[i]][["associated_institutions"]][[j]][["country_code"]])!=0) {
associated_country<-append(associated_country, insts[[i]][["associated_institutions"]][[j]][["country_code"]])
}
else {
associated_country<-append(associated_country, list(c("")))
}
if(length(insts[[i]][["associated_institutions"]][[j]][["type"]])!=0) {
associated_type<-append(associated_type, insts[[i]][["associated_institutions"]][[j]][["type"]])
}
else {
associated_type<-append(associated_type, list(c("")))
}
if(length(insts[[i]][["associated_institutions"]][[j]][["relationship"]])!=0) {
associated_rel<-append(associated_rel, insts[[i]][["associated_institutions"]][[j]][["relationship"]])
}
else {
associated_rel<-append(associated_rel, list(c("")))
}
}
}
else {
associated_id<-append(associated_id, list(c("")))
associated<-append(associated, list(c("")))
associated_country<-append(associated_country, list(c("")))
associated_type<-append(associated_type, list(c("")))
associated_rel<-append(associated_rel, list(c("")))
}
}
associated_id <- associated_id %>% data.frame %>% t()
associated <- associated %>% data.frame %>% t()
associated_country <- associated_country %>% data.frame %>% t()
associated_type <- associated_type %>% data.frame %>% t()
associated_rel <- associated_rel %>% data.frame %>% t()
inst_chars <- cbind(inst_geo, associated, associated_id, associated_country, associated_type, associated_rel) %>%
group_by(inst_id, which_inst) %>%
mutate(which_assoc = 1:n(),
inst_id = str_replace(inst_id, "https://openalex.org/",""),
associated_id = str_replace(associated_id, "https://openalex.org/",""))
write_csv(inst_chars, paste0("../output/inst_geo_chars", as.character(q), ".csv"))
}
set.seed(8975)
library(openalexR)
library(dplyr)
library(ggplot2)
library(here)
library(haven)
library(stringr)
library(purrr)
library(tidyverse)
set.seed(8975)
id_file <- read_dta('../external/ids/list_of_works.dta')
nr <- nrow(id_file)
split_id <- split(id_file, rep(1:ceiling(nr/5000), each = 5000, length.out=nr))
num_file <- length(split_id)
process_article <- function(article) {
if (length(article[["authorships"]]) == 0) return(NULL)
n_authors <- length(article[["authorships"]])
ids <- rep(as.character(article[["id"]]), n_authors)
abstract_len <- rep(as.character(length(article[["abstract_inverted_index"]])), n_authors)
doi <- rep(ifelse(length(article[["doi"]]) != 0, article[["doi"]], ""), n_authors)
jrnl <- rep(ifelse(length(article[["primary_location"]][["source"]][["display_name"]]) != 0, article[["primary_location"]][["source"]][["display_name"]], ""), n_authors)
title <- rep(ifelse(length(article[["title"]]) != 0, article[["title"]], ""), n_authors)
pub_date <- rep(ifelse(length(article[["publication_date"]]) != 0, article[["publication_date"]], ""), n_authors)
retracted <- rep(as.character(ifelse(length(article[["is_retracted"]]) != 0, article[["is_retracted"]], "")), n_authors)
cite_count <- rep(as.character(ifelse(length(article[["cited_by_count"]]) != 0, article[["cited_by_count"]], "")), n_authors)
pub_type <- rep(ifelse(length(article[["type"]]) != 0, article[["type"]], ""), n_authors)
pub_type_crossref <- rep(ifelse(length(article[["type_crossref"]]) != 0, article[["type_crossref"]], ""), n_authors)
pmid <- rep(ifelse(is.null(article[["ids"]][["pmid"]]), "", as.character(article[["ids"]][["pmid"]])), n_authors)
which_athr <- seq_len(n_authors)
author_data <- map_dfr(article[["authorships"]], function(authorship) {
athr_id <- ifelse(is.null(authorship[["author"]][["id"]]), "", authorship[["author"]][["id"]])
athr_pos <- ifelse(is.null(authorship[["author_position"]][[1]]), "", authorship[["author_position"]][[1]])
raw_affl <- ifelse(is.null(authorship[["raw_affiliation_string"]][[1]]), "", authorship[["raw_affiliation_string"]][[1]])
athr_name <- ifelse(is.null(authorship[["author"]][["display_name"]]), "", authorship[["author"]][["display_name"]])
num_affls <- ifelse(is.null(length(authorship[["institutions"]])), 0, length(authorship[["institutions"]]))
tibble(athr_id, athr_pos, raw_affl, athr_name, as.character(num_affls))
})
# Ensure that all the vectors are of equal length
if (nrow(author_data) == n_authors) {
bind_cols(
tibble(ids, abstract_len, doi, jrnl, title, pub_date, retracted, cite_count, pub_type, pub_type_crossref, pmid, which_athr),
author_data
)
} else {
return(NULL)
}
}
for (q in 1:1) {
works_from_ids <- oa_fetch(
entity = "works",
mailto = "conniexu@g.harvard.edu",
id = split_id[[q]] %>% filter(id != "id" & id != "") %>% pull(id),
output = "list"
)
au_ids <- map_dfr(works_from_ids, process_article)
colnames(au_ids) <- c("id", "abstract_len", "doi", "jrnl", "title", "pub_date", "retracted", "cite_count", "pub_type", "pub_type_crossref", "pmid", "which_athr", "athr_id", "athr_pos", "raw_affl", "athr_name", "num_affls")
au_ids <- au_ids %>%
mutate(num_affls = as.numeric(num_affls),
num_affls = replace(num_affls, num_affls == 0, 1)) %>%
uncount(num_affls)
inst <- list()
inst_id <- list()
for (i in seq_along(works_from_ids)) {
article <- works_from_ids[[i]]
if (length(article[["authorships"]]) == 0) next
for (authorship in article[["authorships"]]) {
if (length(authorship[["institutions"]]) == 0) {
inst <- append(inst, "")
inst_id <- append(inst_id, "")
} else {
for (institution in authorship[["institutions"]]) {
inst <- append(inst, ifelse(length(institution[["display_name"]]) != 0, institution[["display_name"]], ""))
inst_id <- append(inst_id, ifelse(length(institution[["id"]]) != 0, institution[["id"]], ""))
}
}
}
}
affl_list <- au_ids %>% mutate(inst = inst, inst_id = inst_id) %>%
group_by(id, which_athr) %>%
mutate(which_affl = 1:n(),
id = str_replace(as.character(id), "https://openalex.org/", ""),
pmid = str_replace(pmid, "https://pubmed.ncbi.nlm.nih.gov/", ""),
athr_id = str_replace(athr_id, "https://openalex.org/", ""),
inst_id = str_replace(inst_id, "https://openalex.org/", ""))
write_csv(affl_list, paste0("../output/openalex_authors", as.character(q), ".csv"))
mesh_terms <- map_dfr(works_from_ids, function(article) {
if (length(article[["mesh"]]) == 0) return(NULL)
ids <- rep(article[["id"]], length(article[["mesh"]]))
which_mesh <- seq_along(article[["mesh"]])
terms <- map_chr(article[["mesh"]], "descriptor_name")
major_topic <- map_lgl(article[["mesh"]], "is_major_topic")
qualifier <- map_chr(article[["mesh"]], ~ ifelse(is.null(.x[["qualifier_name"]]), "", .x[["qualifier_name"]]))
tibble(ids, which_mesh, terms, major_topic, qualifier)
})
colnames(mesh_terms) <- c("id", "which_mesh", "term", "is_major_topic", "qualifier_name")
if (nrow(mesh_terms) != 0) {
mesh_terms <- mesh_terms %>% mutate(id = str_replace(as.character(id), "https://openalex.org/", ""))
#write_csv(mesh_terms, paste0("../output/mesh_terms", as.character(q), ".csv"))
}
concepts <- map_dfr(works_from_ids, function(article) {
if (length(article[["concepts"]]) == 0) return(NULL)
ids <- rep(article[["id"]], length(article[["concepts"]]))
which_concept <- seq_along(article[["concepts"]])
concept_id <- map_chr(article[["concepts"]], "id")
terms <- map_chr(article[["concepts"]], "display_name")
level <- map_int(article[["concepts"]], "level")
score <- map_dbl(article[["concepts"]], "score")
tibble(ids, which_concept, concept_id, terms, level, score)
})
colnames(concepts) <- c("id", "which_concept", "concept_id", "term", "level", "score")
if (nrow(concepts) != 0) {
concepts <- concepts %>% mutate(id = str_replace(as.character(id), "https://openalex.org/", ""),
concept_id = str_replace(as.character(concept_id), "https://openalex.org/", ""))
#write_csv(concepts, paste0("../output/concepts", as.character(q), ".csv"))
}
}
warnings()
library(openalexR)
library(dplyr)
library(ggplot2)
library(here)
library(haven)
library(stringr)
library(purrr)
library(tidyverse)
set.seed(8975)
id_file <- read_dta('../external/ids/list_of_works.dta')
nr <- nrow(id_file)
split_id <- split(id_file, rep(1:ceiling(nr/5000), each = 5000, length.out=nr))
num_file <- length(split_id)
process_article <- function(article) {
if (length(article[["authorships"]]) == 0) return(NULL)
n_authors <- length(article[["authorships"]])
ids <- rep(as.character(article[["id"]]), n_authors)
abstract_len <- rep(as.character(length(article[["abstract_inverted_index"]])), n_authors)
doi <- rep(ifelse(length(article[["doi"]]) != 0, article[["doi"]], ""), n_authors)
jrnl <- rep(ifelse(length(article[["primary_location"]][["source"]][["display_name"]]) != 0, article[["primary_location"]][["source"]][["display_name"]], ""), n_authors)
title <- rep(ifelse(length(article[["title"]]) != 0, article[["title"]], ""), n_authors)
pub_date <- rep(ifelse(length(article[["publication_date"]]) != 0, article[["publication_date"]], ""), n_authors)
retracted <- rep(as.character(ifelse(length(article[["is_retracted"]]) != 0, article[["is_retracted"]], "")), n_authors)
cite_count <- rep(as.character(ifelse(length(article[["cited_by_count"]]) != 0, article[["cited_by_count"]], "")), n_authors)
pub_type <- rep(ifelse(length(article[["type"]]) != 0, article[["type"]], ""), n_authors)
pub_type_crossref <- rep(ifelse(length(article[["type_crossref"]]) != 0, article[["type_crossref"]], ""), n_authors)
pmid <- rep(ifelse(is.null(article[["ids"]][["pmid"]]), "", as.character(article[["ids"]][["pmid"]])), n_authors)
which_athr <- seq_len(n_authors)
author_data <- map_dfr(article[["authorships"]], function(authorship) {
athr_id <- ifelse(is.null(authorship[["author"]][["id"]]), "", authorship[["author"]][["id"]])
athr_pos <- ifelse(is.null(authorship[["author_position"]][[1]]), "", authorship[["author_position"]][[1]])
raw_affl <- ifelse(is.null(authorship[["raw_affiliation_string"]][[1]]), "", authorship[["raw_affiliation_string"]][[1]])
athr_name <- ifelse(is.null(authorship[["author"]][["display_name"]]), "", authorship[["author"]][["display_name"]])
num_affls <- ifelse(is.null(length(authorship[["institutions"]])), 0, length(authorship[["institutions"]]))
tibble(athr_id, athr_pos, raw_affl, athr_name, as.character(num_affls))
})
# Ensure that all the vectors are of equal length
if (nrow(author_data) == n_authors) {
bind_cols(
tibble(ids, abstract_len, doi, jrnl, title, pub_date, retracted, cite_count, pub_type, pub_type_crossref, pmid, which_athr),
author_data
)
} else {
return(NULL)
}
}
for (q in 1:30) {
works_from_ids <- oa_fetch(
entity = "works",
mailto = "conniexu@g.harvard.edu",
id = split_id[[q]] %>% filter(id != "id" & id != "") %>% pull(id),
output = "list"
)
au_ids <- map_dfr(works_from_ids, process_article)
colnames(au_ids) <- c("id", "abstract_len", "doi", "jrnl", "title", "pub_date", "retracted", "cite_count", "pub_type", "pub_type_crossref", "pmid", "which_athr", "athr_id", "athr_pos", "raw_affl", "athr_name", "num_affls")
au_ids <- au_ids %>%
mutate(num_affls = as.numeric(num_affls),
num_affls = replace(num_affls, num_affls == 0, 1)) %>%
uncount(num_affls)
inst <- list()
inst_id <- list()
for (i in seq_along(works_from_ids)) {
article <- works_from_ids[[i]]
if (length(article[["authorships"]]) == 0) next
for (authorship in article[["authorships"]]) {
if (length(authorship[["institutions"]]) == 0) {
inst <- append(inst, "")
inst_id <- append(inst_id, "")
} else {
for (institution in authorship[["institutions"]]) {
inst <- append(inst, ifelse(length(institution[["display_name"]]) != 0, institution[["display_name"]], ""))
inst_id <- append(inst_id, ifelse(length(institution[["id"]]) != 0, institution[["id"]], ""))
}
}
}
}
affl_list <- au_ids %>% mutate(inst = inst, inst_id = inst_id) %>%
group_by(id, which_athr) %>%
mutate(which_affl = 1:n(),
id = str_replace(as.character(id), "https://openalex.org/", ""),
pmid = str_replace(pmid, "https://pubmed.ncbi.nlm.nih.gov/", ""),
athr_id = str_replace(athr_id, "https://openalex.org/", ""),
inst_id = str_replace(inst_id, "https://openalex.org/", ""))
write_csv(affl_list, paste0("../output/openalex_authors", as.character(q), ".csv"))
mesh_terms <- map_dfr(works_from_ids, function(article) {
if (length(article[["mesh"]]) == 0) return(NULL)
ids <- rep(article[["id"]], length(article[["mesh"]]))
which_mesh <- seq_along(article[["mesh"]])
terms <- map_chr(article[["mesh"]], "descriptor_name")
major_topic <- map_lgl(article[["mesh"]], "is_major_topic")
qualifier <- map_chr(article[["mesh"]], ~ ifelse(is.null(.x[["qualifier_name"]]), "", .x[["qualifier_name"]]))
tibble(ids, which_mesh, terms, major_topic, qualifier)
})
colnames(mesh_terms) <- c("id", "which_mesh", "term", "is_major_topic", "qualifier_name")
if (nrow(mesh_terms) != 0) {
mesh_terms <- mesh_terms %>% mutate(id = str_replace(as.character(id), "https://openalex.org/", ""))
#write_csv(mesh_terms, paste0("../output/mesh_terms", as.character(q), ".csv"))
}
concepts <- map_dfr(works_from_ids, function(article) {
if (length(article[["concepts"]]) == 0) return(NULL)
ids <- rep(article[["id"]], length(article[["concepts"]]))
which_concept <- seq_along(article[["concepts"]])
concept_id <- map_chr(article[["concepts"]], "id")
terms <- map_chr(article[["concepts"]], "display_name")
level <- map_int(article[["concepts"]], "level")
score <- map_dbl(article[["concepts"]], "score")
tibble(ids, which_concept, concept_id, terms, level, score)
})
colnames(concepts) <- c("id", "which_concept", "concept_id", "term", "level", "score")
if (nrow(concepts) != 0) {
concepts <- concepts %>% mutate(id = str_replace(as.character(id), "https://openalex.org/", ""),
concept_id = str_replace(as.character(concept_id), "https://openalex.org/", ""))
#write_csv(concepts, paste0("../output/concepts", as.character(q), ".csv"))
}
}
library(openalexR)
library(dplyr)
library(ggplot2)
library(here)
library(haven)
library(stringr)
library(purrr)
library(tidyverse)
set.seed(8975)
################################### MAIN ###################################
insts <- read_dta('../output/list_of_insts.dta')
nr <- nrow(insts)
split_insts <- split(insts, rep(1:ceiling(nr/5000), each = 5000, length.out=nr))
num_file <- length(split_insts)
for (q in 1:1) {
insts <- oa_fetch(
entity = "institutions",
id  = split_insts[[q]] %>%  mutate(inst_id = as.character(inst_id)) %>% pull(inst_id),
verbose = TRUE,
output = "list"
)
N_insts <- length(insts)
inst_geo <- lapply(1:N_insts, function(i) {
if (length(insts[[i]][["id"]])!=0) {
inst_id <- insts[[i]][["id"]] %>% data.frame
}
if (length(insts[[i]][["display_name"]])!=0) {
inst <-  insts[[i]][["display_name"]] %>% data.frame
}
else {
inst <- c("")%>% data.frame
}
if (length(insts[[i]][["country_code"]])!=0) {
country_code <- insts[[i]][["country_code"]] %>% data.frame
}
else {
country_code <- c("")%>% data.frame
}
if (length(insts[[i]][["type"]])!=0) {
type <- insts[[i]][["type"]] %>% data.frame
}
else {
type <- c("")%>% data.frame
}
if (length(insts[[i]][["geo"]][["city"]])!=0) {
city <- insts[[i]][["geo"]][["city"]]%>% data.frame
}
else {
city <- c("")%>% data.frame
}
if (length(insts[[i]][["geo"]][["country"]])!=0) {
country <- insts[[i]][["geo"]][["country"]]%>% data.frame
}
else {
country <- c("")%>% data.frame
}
if (length(insts[[i]][["geo"]][["region"]])!=0) {
region <- insts[[i]][["geo"]][["region"]]%>% data.frame
}
else {
region <- c("")%>% data.frame
}
num_assocs <-length(insts[[i]][["associated_institutions"]])%>% data.frame
cbind(inst_id, inst, country_code, country, city, region, type, num_assocs)
}) %>% bind_rows()
colnames(inst_geo) <- c("inst_id","inst", "country_code", "country", "city", "region", "type", "num_assocs")
inst_geo <- inst_geo %>%
mutate(which_inst = 1:n(),
num_assocs = replace(num_assocs, num_assocs == 0, 1)) %>%
uncount(num_assocs)
associated_id <- list()
associated <- list()
associated_country <- list()
associated_type <- list()
associated_rel <- list()
for(i in 1:N_insts) {
N_assocs <- length(insts[[i]][["associated_institutions"]])
if (N_assocs !=0) {
for(j in 1:N_assocs) {
if(length(insts[[i]][["associated_institutions"]][[j]][["id"]])!=0) {
associated_id<-append(associated_id, insts[[i]][["associated_institutions"]][[j]][["id"]])
}
else {
associated_id<-append(associated_id, list(c("")))
}
if(length(insts[[i]][["associated_institutions"]][[j]][["display_name"]])!=0) {
associated<-append(associated, insts[[i]][["associated_institutions"]][[j]][["display_name"]])
}
else {
associated<-append(associated, list(c("")))
}
if(length(insts[[i]][["associated_institutions"]][[j]][["country_code"]])!=0) {
associated_country<-append(associated_country, insts[[i]][["associated_institutions"]][[j]][["country_code"]])
}
else {
associated_country<-append(associated_country, list(c("")))
}
if(length(insts[[i]][["associated_institutions"]][[j]][["type"]])!=0) {
associated_type<-append(associated_type, insts[[i]][["associated_institutions"]][[j]][["type"]])
}
else {
associated_type<-append(associated_type, list(c("")))
}
if(length(insts[[i]][["associated_institutions"]][[j]][["relationship"]])!=0) {
associated_rel<-append(associated_rel, insts[[i]][["associated_institutions"]][[j]][["relationship"]])
}
else {
associated_rel<-append(associated_rel, list(c("")))
}
}
}
else {
associated_id<-append(associated_id, list(c("")))
associated<-append(associated, list(c("")))
associated_country<-append(associated_country, list(c("")))
associated_type<-append(associated_type, list(c("")))
associated_rel<-append(associated_rel, list(c("")))
}
}
associated_id <- associated_id %>% data.frame %>% t()
associated <- associated %>% data.frame %>% t()
associated_country <- associated_country %>% data.frame %>% t()
associated_type <- associated_type %>% data.frame %>% t()
associated_rel <- associated_rel %>% data.frame %>% t()
inst_chars <- cbind(inst_geo, associated, associated_id, associated_country, associated_type, associated_rel) %>%
group_by(inst_id, which_inst) %>%
mutate(which_assoc = 1:n(),
inst_id = str_replace(inst_id, "https://openalex.org/",""),
associated_id = str_replace(associated_id, "https://openalex.org/",""))
write_csv(inst_chars, paste0("../output/inst_geo_chars", as.character(q), ".csv"))
}
