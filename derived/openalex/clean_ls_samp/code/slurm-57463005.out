[?1h=
  ___  ____  ____  ____  ____ Â©
 /__    /   ____/   /   ____/      17.0
___/   /   /___/   /   /___/       MPâ€”Parallel Edition

 Statistics and Data Science       Copyright 1985-2021 StataCorp LLC
                                   StataCorp
                                   4905 Lakeway Drive
                                   College Station, Texas 77845 USA
                                   800-STATA-PC        https://www.stata.com
                                   979-696-4600        stata@stata.com

Stata license: 32-user 64-core network perpetual
Serial number: 501706311472
  Licensed to: Harvard Research Computing
               Cambridge MA

Notes:
      1. Unicode is supported; see help unicode_advice.
      2. More than 2 billion observations are allowed; see help obs_advice.
      3. Maximum number of variables is set to 120,000; see help set_maxvar.

. do "build.do" 

. set more off

. clear all

. capture log close

. program drop _all

. set scheme modern

. pause on

. set seed 8975

. set maxvar 120000


. 
. program main
  1.     // samp: all_jrnls_merged, _1...6, top_jrnls
.     local samp "top_jrnls"
  2.     clean_titles, samp(`samp')
  3.     clean_samps, samp(`samp')
  4.     clean_mesh, samp(`samp')
  5. end

. 
. program clean_titles
  1.     syntax, samp(str) 
  2.     if "`samp'" == "top_jrnls" local fol top
  3.     if strpos("`samp'" , "all_jrnls")  > 0 local fol samp 
  4.     use pmid title id pub_type jrnl using ../external/`fol'/openalex_`samp
> '_merged, clear
  5.     replace title = stritrim(title)
  6.     contract title id pmid jrnl
  7.     gduplicates drop pmid , force
  8.     gduplicates drop id  , force
  9.     cap drop _freq
 10.     gisid id
 11.     drop if mi(title)
 12.     gen lower_title = stritrim(subinstr(subinstr(subinstr(subinstr(strlowe
> r(title), `"""', "", .), ".", "",.)), " :", ":",.), "'", "", .)
 13.     drop if strpos(lower_title, "accountable care")>0 | strpos(title, "ACO
> s")>0
 14.     drop if lower_title == "response"
 15.     drop if strpos(lower_title , "nuts")>0 & strpos(lower_title, "bolts")>
> 0
 16.     foreach s in "economic" "economy" "public health" "hallmarks" "governm
> ent" "reform" "equity" "payment" "politics" "policy" "policies" "comment" "gu
> ideline" "profession's" "interview" "debate" "professor" "themes:"  "professi
> onals" "physician" "workforce" "medical-education"  "medical education" "fund
> ing" "conference" "insurance" "fellowship" "ethics" "legislation" "the editor
> " "response : " "letters" "this week" "notes" "news " "a note" "obituary"  "r
> eview" "perspectives" "scientists" "book" "institution" "meeting" "university
> " "universities" "journals" "publication" "recent " "costs" "challenges" "res
> earchers" "perspective" "reply" " war" " news" "a correction" "academia" "soc
> iety" "academy of" "nomenclature" "teaching" "education" "college" "academics
> "  "political" "association for" "association of" "response by" "societies" "
> health care" "health-care"  "abstracts" "journal club" "curriculum" "women in
>  science" "report:" "letter:" "editorial:" "lesson" "awards" "doctor" "nurse"
>  "health workers" " story"  "case report" "a brief history" "lecture " "caree
> r" "finance" "criticism" "critique" "discussion" "world health" "workload" "c
> ompensation" "educators" "war" "announces" "training programmes" "nhs" "nih" 
> "national institutes of health" "address" "public sector" "private sector" "g
> overnment" "price" "reflections" "health care" "healthcare" "health-care" " l
> aw" "report" "note on" "insurer" "health service research" "error" "quality o
> f life" {
 17.         drop if strpos(lower_title, "`s'")>0
 18.     }
 19.     gen strp = substr(lower_title, 1, strpos(lower_title, ": ")) if strpos
> (lower_title, ": ") > 0
 20.     bys strp jrnl : gen tot_strp = _N
 21.     foreach s in "letter:" "covid-19:" "snapshot:" "editorial:" "david oli
> ver:" "offline:" "helen salisbury:" "margaret mccartney:" "book:" "response:"
>  "letter from chicago:" "a memorable patient:" "<i>response</i> :" "reading f
> or pleasure:" "partha kar" "venus:" "matt morgan:" "bad medicine:" "nota bene
> :" "cohort profile:" "size matters:" "usa:" "cell of the month:" "living on t
> he edge:" "enhanced snapshot:" "world view:" "science careers:" "clare gerada
> :" "rammya mathew:" "endpiece:" "role model:" "quick uptakes:" "webiste of th
> e week:" "tv:" "press:" "brief communication:" "essay:" "clinical update:" "a
> ssisted dying:" "controversies in management:" "health agencies update:" "the
>  bmj awards 2020:" "lesson of the week:" "ebola:" "media:" "management for do
> ctors:" "monkeypox:" "profile:" "the bmj awards 2017:" "the world in medicine
> :" "the bmj awards 2021:" "when i use a word . . .:" "personal paper:"  "clin
> ical decision making:" "how to do it:" "10-minute consultation:" "frontline:"
>  "when i use a word:" "medicine as a science:" "personal papers:" "miscellane
> a:" "the lancet technology:" {
 22.         drop if strpos(lower_title, "`s'") == 1 & tot_strp > 1
 23.     }
 24.     drop if inlist(lower_title, "random samples", "sciencescope", "through
>  the glass lightly", "equipment", "women in science",  "correction", "the met
> ric system")
 25.     drop if inlist(lower_title, "convocation week","the new format", "seco
> nd-quarter biotech job picture", "gmo roundup")
 26.     drop if strpos(lower_title, "annals ")==1
 27.     drop if strpos(lower_title, "a fatal case of")==1
 28.     drop if strpos(lower_title, "a case of ")==1
 29.     drop if strpos(lower_title, "case ")==1
 30.     drop if strpos(lower_title, "a day ")==1
 31.     drop if strpos(lower_title,"?")>0
 32.     preserve
 33.     contract lower_title jrnl  pmid
 34.     gduplicates tag lower_title jrnl, gen(dup)
 35.     keep if dup> 0 & jrnl != "jbc"
 36.     keep pmid
 37.     gduplicates drop
 38.     save ../temp/possible_non_articles_`samp', replace
 39.     restore
 40.     merge m:1 pmid using ../temp/possible_non_articles_`samp', assert(1 3)
>  keep(1) nogen
 41.     save ../temp/openalex_`samp'_clean_titles, replace
 42. end

. 
. program clean_samps
  1.     syntax, samp(str) 
  2.     if "`samp'" == "top_jrnls" local fol top
  3.     if strpos("`samp'" , "all_jrnls")  > 0 local fol samp 
  4.     use id jrnl pmid using ../temp/openalex_`samp'_clean_titles, clear
  5.     merge 1:m id using ../external/`fol'/openalex_`samp'_merged, assert(1 
> 2 3) keep(3) nogen 
  6.     merge m:1 id using ../external/patents/patent_ppr_cnt, assert(1 2 3) k
> eep(1 3) nogen keepusing(patent_count front_only body_only)
  7.     // clean date variables
.     gen date = date(pub_date, "YMD")
  8.     format %td date
  9.     drop pub_date
 10.     bys id: gegen min_date = min(date)
 11.     replace date =min_date
 12.     drop min_date
 13.     cap drop author_id
 14.     rename date pub_date
 15.     gen pub_mnth = month(pub_date)
 16.     gen year = year(pub_date)
 17.     gen qrtr = qofd(pub_date)
 18.     drop if year < 1945
 19.     // fix some wrong institutions
.     replace inst = "Johns Hopkins University" if strpos(raw_affl , "Bloomberg
>  School of Public Health")>0 & inst == "Bloomberg (United States)"
 20.     merge m:1 inst_id using ../external/inst_xw/all_inst_geo_chars, assert
> (1 2 3) keep(1 3) nogen 
 21.     replace inst = new_inst if !mi(new_inst)
 22.     replace inst_id = new_inst_id if !mi(new_inst)
 23.     replace inst = "Johns Hopkins University" if  strpos(inst, "Johns Hopk
> ins")>0
 24.     replace inst_id = "I145311948" if inst == "Johns Hopkins University"
 25.     replace inst = "Stanford University" if inlist(inst, "Stanford Medicin
> e", "Stanford Health Care")
 26.     replace inst = "Northwestern University" if inlist(inst, "Northwestern
>  Medicine")
 27.     replace inst = "National Institutes of Health" if  inlist(inst, "Natio
> nal Cancer Institute", "National Eye Institute", "National Heart, Lung, and B
> lood Institute", "National Human Genome Research Institute") | ///
>               inlist(inst, "National Institute on Aging", "National Institute
>  on Alcohol Abuse and Alcoholism", "National Institute of Allergy and Infecti
> ous Diseases", "National Institute of Arthritis and Musculoskeletal and Skin 
> Diseases") | ///
>                         inlist(inst, "National Institute of Biomedical Imagin
> g and Bioengineering", "National Institute of Child Health and Human Developm
> ent", "National Institute of Dental and Craniofacial Research") | ///
>                                   inlist(inst, "National Institute of Diabete
> s and Digestive and Kidney Diseases", "National Institute on Drug Abuse", "Na
> tional Institute of Environmental Health Sciences", "National Institute of Ge
> neral Medical Sciences", "National Institute of Mental Health", "National Ins
> titute on Minority Health and Health Disparities") | ///
>                                             inlist(inst, "National Institute 
> of Neurological Disorders and Stroke", "National Institute of Nursing Researc
> h", "National Library of Medicine", "National Heart Lung and Blood Institute"
> , "National Institutes of Health")
 28.     // drop any authors that are journals - these are probably reviews 
.     gen is_lancet = strpos(raw_affl, "The Lancet")>0
 29.     gen is_london = raw_affl == "London, UK." |  raw_affl == "London."
 30.     gen is_bmj = (strpos(raw_affl, "BMJ")>0 | strpos(raw_affl, "British Me
> dical Journal")>0)
 31.     gen is_jama = strpos(raw_affl, " JAMA")>0 & mi(inst)
 32.     gen is_editor = strpos(raw_affl, " Editor")>0 | strpos(raw_affl, "Edit
> or ")>0
 33.     bys pmid: gegen has_lancet = max(is_lancet)
 34.     by pmid: gegen has_london = max(is_london)
 35.     by pmid: gegen has_bmj = max(is_bmj)
 36.     by pmid: gegen has_jama = max(is_jama)
 37.     by pmid: gegen has_editor = max(is_jama)
 38.     drop if has_lancet == 1 | has_london == 1 | has_bmj == 1 | has_jama ==
>  1 | has_editor == 1
 39.     drop is_lancet is_london is_bmj is_jama is_editor has_lancet has_londo
> n has_bmj has_jama has_editor
 40.     // add in cite_ct
. *    replace cite_count = cite_count + 1
. *    assert cite_count > 0 
. 
.     save ../temp/cleaned_all_`samp', replace 
 41.     
.     cap drop author_id 
 42.     cap drop which_athr_counter num_which_athr min_which_athr which_athr2 
 43.     bys pmid athr_id (which_athr which_affl): gen author_id = _n ==1
 44.     bys pmid (which_athr which_affl): gen which_athr2 = sum(author_id)
 45.     replace which_athr = which_athr2
 46.     drop which_athr2
 47.     bys pmid which_athr: gen num_affls = _N
 48.     cap drop region 
 49.     cap drop inst_id 
 50.     cap drop country
 51.     cap drop country_code
 52.     cap drop city 
 53.     cap drop inst
 54.     cap drop new_inst new_inst_id 
 55.     merge m:1 athr_id year using ../external/year_insts/filled_in_panel_ye
> ar_1945_2025, assert(1 2 3) keep(3) nogen
 56.     gduplicates drop pmid athr_id inst_id, force
 57.     save ../temp/cleaned_all_`samp'_prewt, replace
 58. 
.     use ../temp/cleaned_all_`samp'_prewt, clear
 59.     // wt_adjust articlesj
.     qui hashsort pmid which_athr which_affl
 60.     cap drop author_id
 61.     bys pmid athr_id (which_athr which_affl): gen author_id = _n ==1
 62.     bys pmid (which_athr which_affl): gen which_athr2 = sum(author_id)
 63.     replace which_athr = which_athr2
 64.     drop which_athr2
 65.     bys pmid which_athr: replace num_affls = _N
 66.     assert num_affls == 1
 67.     bys pmid: gegen num_athrs = max(which_athr)
 68.     gen affl_wt = 1/num_affls * 1/num_athrs // this just divides each pape
> r by the # of authors on the paper
 69.     gen pat_affl_wt = patent_count * 1/num_affls * 1/num_athrs
 70.     gen body_affl_wt = body_only * 1/num_affls * 1/num_athrs
 71.     gen front_affl_wt = front_only * 1/num_affls * 1/num_athrs
 72. 
.     // now give each article a weight based on their ciatation count 
.     qui gen years_since_pub = 2025-year+1
 73.     qui gen avg_cite_yr = cite_count/years_since_pub
 74.     qui gen avg_pat_yr = patent_count/years_since_pub
 75.     qui gen avg_frnt_yr = front_only/years_since_pub
 76.     qui gen avg_body_yr = body_only/years_since_pub
 77.     qui bys pmid: replace avg_cite_yr = . if _n != 1
 78.     qui bys pmid: replace avg_pat_yr = . if _n != 1
 79.     qui bys pmid: replace avg_frnt_yr = . if _n != 1
 80.     qui bys pmid: replace avg_body_yr = . if _n != 1
 81.     qui sum avg_cite_yr
 82.     gen cite_wt = avg_cite_yr/r(sum) // each article is no longer weighted
>  1 
 83.     qui sum avg_pat_yr
 84.     gen pat_wt = avg_pat_yr/r(sum) 
 85.     qui sum avg_frnt_yr
 86.     gen frnt_wt = avg_frnt_yr/r(sum) 
 87.     qui sum avg_body_yr
 88.     gen body_wt = avg_body_yr/r(sum) 
 89.     bys jrnl: gegen tot_cite_N = total(cite_wt)
 90.     gsort pmid cite_wt
 91.     qui bys pmid: replace cite_wt = cite_wt[_n-1] if mi(cite_wt)
 92.     gsort pmid pat_wt
 93.     qui bys pmid: replace pat_wt = pat_wt[_n-1] if mi(pat_wt)
 94.     gsort pmid frnt_wt
 95.     qui bys pmid: replace frnt_wt = frnt_wt[_n-1] if mi(frnt_wt)
 96.     gsort pmid body_wt
 97.     qui bys pmid: replace body_wt = body_wt[_n-1] if mi(body_wt)
 98.     qui gunique pmid
 99.     local articles = r(unique)
100.     qui gen cite_affl_wt = affl_wt * cite_wt * `articles'
101.     qui gen pat_adj_wt  = affl_wt * pat_wt * `articles'
102.     qui gen frnt_adj_wt  = affl_wt * frnt_wt * `articles'
103.     qui gen body_adj_wt  = affl_wt * body_wt * `articles'
104.    
.     qui bys id: gen id_cntr = _n == 1
105.     qui bys jrnl: gen first_jrnl = _n == 1
106.     qui by jrnl: gegen jrnl_N = total(id_cntr)
107.     *qui sum impact_fctr if first_jrnl == 1
.     *gen impact_shr = impact_fctr/r(sum) // weight that each journal gets
.     *gen reweight_N = impact_shr * `articles' // adjust the N of each journal
>  to reflect impact factor
.     *replace  tot_cite_N = tot_cite_N * `articles'
.     *gen impact_wt = reweight_N/jrnl_N // after adjusting each journal weight
>  we divide by the number of articles in each journal to assign new weight to 
> each paper
.     *gen impact_affl_wt = impact_wt * affl_wt  
.     *gen impact_cite_wt = reweight_N * cite_wt / tot_cite_N * `articles' 
.     *gen impact_cite_affl_wt = impact_cite_wt * affl_wt 
.     foreach wt in affl_wt cite_affl_wt pat_adj_wt { // frnt_adj_wt body_adj_w
> t { // impact_affl_wt impact_cite_affl_wt 
108.         sum `wt'
109.         assert round(r(sum)-`articles') == 0
110.     }
111.     compress, nocoalesce
112.     gen len = length(inst)
113.     qui sum len
114.     local n = r(max)
115.     recast str`n' inst, force
116.     cap drop n mi_inst has_nonmi_inst population len
117.     save ../temp/pre_save, replace
118. 
.     import delimited using ../external/geo/us_cities_states_counties.csv, cle
> ar varnames(1)
119.     glevelsof statefull , local(state_names)
120. 
.     use ../temp/pre_save, clear
121.     replace country = "United States" if country_code == "US"
122.     replace country_code = "US" if country == "United States" 
123.     foreach s in `state_names' {
124.         replace region = "`s'" if mi(region) & country_code == "US" & strp
> os(inst, "`s'")>0
125.     }
126.     replace region = "Pennsylvania" if country_code == "US" & inlist(city,
>  "Pittsburgh" , "Philadelphia", "Radnor", "Swarthmore", "Meadville", "Lancast
> er" , "Wilkes-Barre")  
127.     replace region = "California" if country_code == "US" & inlist(city, "
> Stanford", "Los Angeles", "San Diego", "La Jolla", "Berkeley", "San Francisco
> ", "Thousand Oaks", "Mountain View", "Sunnyvale")
128.     replace region = "California" if country_code == "US" & inlist(city, "
> Cupertino", "Malibu", "Torrance", "San Carlos", "Escondido")
129.     replace region = "California" if country_code == "US" & inlist(city, "
> Novato", "Arcata", "Claremont", "Santa Clara", "Castroville", "Pomona", "Emer
> yville", "Redwood City", "Santa Barbara")
130.     replace region = "California" if country_code == "US" & inlist(city, "
> San Jose", "South San Francisco", "Pasadena", "Irving", "La CaÃ±ada Flintridge
> ", "Duarte", "Menlo Park", "Livermore")
131.     replace region = "Massachusetts" if country_code == "US" & inlist(city
> , "Boston", "Cambridge", "Medford", "Wellesley", "Falmouth", "Woods Hole", "F
> ramingham", "Plymouth", "Worcester")
132.     replace region = "Massachusetts" if country_code == "US" & inlist(city
> , "Amherst", "Amherst Center", "Waltham", "Northampton", "South Hadley", "And
> over", "Natick", "Newton")
133.     replace region = "Maryland" if country_code == "US" & inlist(city, "Be
> thesda", "Baltimore", "Silver Spring", "Greenbelt", "Gaithersburg", "Frederic
> k", "Riverdale Park", "Rockville", "Annapolis")
134.     replace region = "Maryland" if country_code == "US" & inlist(city, "To
> wson", "College Park", "Edgewater")
135.     replace region = "Ohio" if country_code == "US" & inlist(city, "Toledo
> ", "Dayton", "Oxford", "Cleveland", "Ardmore", "Oberlin", "Cincinnati", "Colu
> mbus")
136.     replace region = "New Jersey" if country_code == "US" & inlist(city, "
> New Brunswick", "Bridgewater", "Hoboken", "Raritan", "Glassboro", "Whippany",
>  " Woodcliff Lake", "South Plainfield")
137.     replace region = "New Jersey" if country_code == "US" & inlist(city, "
> Montclair", "Princeton", "Woodcliff Lake")
138.     replace region = "Iowa" if country_code == "US" & inlist(city, "Ames",
>  "Des Moines")
139.     replace region = "Nevada" if country_code == "US" & inlist(city, "Reno
> ")
140.     replace region = "Nebraska" if country_code == "US" & inlist(city, "Om
> aha")
141.     replace region = "Oklahoma" if country_code == "US" & inlist(city, "Tu
> lsa")
142.     replace region = "Arizona" if country_code == "US" & inlist(city, "Pho
> enix", "Tucson")
143.     replace region = "Illinois" if country_code == "US" & inlist(city, "Ch
> icago", "Evanston", "Downers Grove", "Hines")
144.     replace region = "Indiana" if country_code == "US" & inlist(city, "Wes
> t Lafayette", "Notre Dame", "Indianapolis", "Fort Wayne")
145.     replace region = "New York" if country_code == "US" & inlist(city, "Ne
> w York", "Ithaca", "Bronx", "Rochester", "Cold Spring Harbor", "Syracuse", "U
> pton", "Albany", "Manhasset")
146.     replace region = "New York" if country_code == "US" & inlist(city,  "B
> rooklyn", "Potsdam", "Tarrytown", "Town of Poughkeepsie", "Saratoga Springs",
>  "Millbrook", "Utica")
147.     replace region = "New York" if country_code == "US" & inlist(city, "Bi
> nghamton", "Brookville", "Hempstead", "Saranac Lake", "New Hyde Park", "Pough
> keepsie", "Buffalo", "Niskayuna")
148.     replace region = "Connecticut" if country_code == "US" & inlist(city, 
> "New Haven", "West Haven", "Fairfield", "Stamford", "West Hartford")
149.     replace region = "Oregon" if country_code == "US" & inlist(city, "Port
> land")
150.     replace region = "Alabama" if country_code == "US" & inlist(city, "Tus
> kegee", "Mobile")
151.     replace region = "District of Columbia" if country_code == "US" & inli
> st(city, "Washington")
152.     replace region = "North Carolina" if country_code == "US" & inlist(cit
> y, "Durham", "Asheville", "Chapel Hill", "Winston Salem", "Boone", "Charlotte
> ")
153.     replace region = "South Carolina" if country_code == "US" & inlist(cit
> y, "Greenville", "Aiken", "Charleston")
154.     replace region = "Wisconsin" if country_code == "US" & inlist(city, "M
> adison", "Milwaukee")
155.     replace region = "Florida" if country_code == "US" & inlist(city, "Cor
> al Gables", "Miami", "Sarasota", "Orlando", "Tampa")
156.     replace region = "Maine" if country_code == "US" & inlist(city, "Lewis
> ton", "Bar Harbor", "Brunswick")
157.     replace region = "Washington" if country_code == "US" & inlist(city, "
> Seattle", "Richland", "Bothell", "Redmond")
158.     replace region = "Colorado" if country_code == "US" & inlist(city, "De
> nver", "Boulder", "Fort Collins", "Golden")
159.     replace region = "Louisiana" if country_code == "US" & inlist(city, "N
> ew Orleans", "Houma")
160.     replace region = "Delaware" if country_code == "US" & inlist(city, "Wi
> lmington")
161.     replace region = "Tennessee" if country_code == "US" & inlist(city, "M
> emphis", "Oak Ridge", "Nashville")
162.     replace region = "Georgia" if country_code == "US" & inlist(city, "Atl
> anta", "Augusta", "Macon", "Decatur", "Kennesaw")
163.     replace region = "Texas" if country_code == "US" & inlist(city, "Houst
> on", "Dallas", "San Antonio", "The Woodlands", "Austin")
164.     replace region = "New Mexico" if country_code == "US" & inlist(city, "
> Los Alamos", "Carlsbad", "Albuquerque", "Santa Fe")
165.     replace region = "Michigan" if country_code == "US" & inlist(city, "An
> n Arbor", "Detroit", "Flint", "Midland", "Royal Oak", "Grand Rapids")
166.     replace region = "Rhode Island" if country_code == "US" & inlist(city,
>  "Providence")
167.     replace region = "Hawaii" if country_code == "US" & inlist(city, "Hono
> lulu")
168.     replace region = "Missouri" if country_code == "US" & inlist(city, "St
>  Louis", "Kirksville")
169.     replace region = "Mississippi" if country_code == "US" & inlist(city, 
> "Vicksburg")
170.     replace region = "Minnesota" if country_code == "US" & inlist(city, "M
> inneapolis", "Saint Paul")
171.     replace region = "Virginia" if country_code == "US" & inlist(city, "Re
> ston", "Williamsburg", "North Laurel", "Arlington", "Richmond", "Harrisonburg
> ", "Front Royal", "Falls Church", "Charlottesville")
172.     replace region = "Virginia" if country_code == "US" & inlist(city, "Ty
> sons Corner", "Fairfax", "Ashburn", "Alexandria")
173.     replace region = "New Hampshire" if country_code == "US" & inlist(city
> , "Hanover", "Lebanon")
174.     replace region = "Illinois" if country_code == "US" & inlist(city, "Le
> mont", "North Chicago")
175.     replace region = "Utah" if country_code == "US" & inlist(city, "Provo"
> , "Salt Lake City")
176.     replace region = "Missouri" if inst_id == "I4210102181"
177.     replace region = "New Jersey" if inst_id == "I150569930"
178.     replace region = "Maryland" if inst_id == "I166416128"
179.     replace region = "Iowa" if inst == "Pioneer Hi-Bred"
180.     replace region = "Iowa" if inst == "WinnMed"
181.     save ../temp/fill_msa, replace
182. 
.     import delimited using ../external/geo/us_cities_states_counties.csv, cle
> ar varnames(1)
183.     gcontract stateshort statefull
184.     cap drop _freq
185.     drop if mi(stateshort)
186.     rename statefull region
187.     merge 1:m region using ../temp/fill_msa, assert(1 2 3) keep(2 3) nogen
188.     replace stateshort =  "DC" if region == "District of Columbia"
189.     replace stateshort =  "VI" if region == "Virgin Islands, U.S."
190.     replace us_state = stateshort if country_code == "US" & mi(us_state)
191.     replace city = "Saint Louis" if city == "St Louis"
192.     replace city = "Winston Salem" if city == "Winston-Salem"
193.     merge m:1 city us_state using ../external/geo/city_msa, assert(1 2 3) 
> keep(1 3) nogen
194.     replace msatitle = "Washington-Arlington-Alexandria, DC-VA-MD-WV"  if 
> us_state == "DC"
195.     replace msatitle = "New York-Newark-Jersey City, NY-NJ-PA" if city == 
> "The Bronx" & us_state == "NY"
196.     replace msatitle = "Miami-Fort Lauderdale-West Palm Beach, FL" if city
>  == "Coral Gables" & us_state == "FL"
197.     replace msatitle = "Springfield, MA" if city == "Amherst Center"
198.     replace msatitle = "Hartford-West Hartford-East Hartford, CT" if city 
> == "Storrs" & us_state == "CT"
199.     replace msatitle = "Tampa-St. Petersburg-Clearwater, FL" if city == "T
> emple Terrace" & us_state == "FL"
200.     replace msatitle = "San Francisco-Oakland-Hayward, CA" if city == "Fos
> ter City" & us_state == "CA"
201.     replace msa_comb = msatitle if mi(msa_comb)
202.     replace  msa_comb = "Research Triangle Park, NC" if msa_comb == "Durha
> m-Chapel Hill, NC" | msa_comb == "Raleigh, NC" | city == "Res Triangle Pk" | 
> city == "Research Triangle Park" | city == "Res Triangle Park"
203.     replace  msa_comb = "Bay Area, CA" if inlist(msa_comb, "San Francisco-
> Oakland-Hayward, CA", "San Jose-Sunnyvale-Santa Clara, CA")
204.     replace msa_c_world = msa_comb if mi(msa_c_world)
205.     replace msa_c_world = substr(msa_c_world, 1, strpos(msa_c_world, ", ")
> -1) + ", US" if country == "United States" & !mi(msa_c_world)
206.     replace msa_c_world = city + ", " + country_code if country_code != "U
> S" & !mi(city) & !mi(country_code)
207.     save ../output/cleaned_`samp', replace
208.     preserve
209.     gcontract id pmid
210.     cap drop _freq
211.     save ../temp/pmid_id_xwalk_`samp', replace
212.     restore
213. 
.     use ../output/cleaned_`samp', clear
214.     keep if inrange(pub_date, td(01jan2005), td(31dec2025)) & year >=2005
215.     drop cite_wt cite_affl_wt tot_cite_N first_jrnl pat_wt pat_adj_wt frnt
> _wt body_wt frnt_adj_wt body_adj_wt jrnl_N 
216.     foreach var in impact_wt impact_affl_wt impact_cite_wt impact_cite_aff
> l_wt impact_shr  reweight_N  {
217.         cap drop `var'
218.     }
219.     qui sum avg_cite_yr
220.     gen cite_wt = avg_cite_yr/r(sum)
221.     qui sum avg_pat_yr
222.     gen pat_wt = avg_pat_yr/r(sum)
223.     qui sum avg_frnt_yr
224.     gen frnt_wt = avg_frnt_yr/r(sum) 
225.     qui sum avg_body_yr
226.     gen body_wt = avg_body_yr/r(sum) 
227.     bys jrnl: gegen tot_cite_N = total(cite_wt)
228.     gsort pmid cite_wt
229.     qui bys pmid: replace cite_wt = cite_wt[_n-1] if mi(cite_wt)
230.     gsort pmid pat_wt
231.     qui bys pmid: replace pat_wt = pat_wt[_n-1] if mi(pat_wt)
232.     gsort pmid frnt_wt
233.     qui bys pmid: replace frnt_wt = frnt_wt[_n-1] if mi(frnt_wt)
234.     gsort pmid body_wt
235.     qui bys pmid: replace body_wt = body_wt[_n-1] if mi(body_wt)
236.     gunique pmid 
237.     local articles = r(unique)
238.     qui gen cite_affl_wt = affl_wt * cite_wt * `articles'
239.     qui gen pat_adj_wt  = affl_wt * pat_wt * `articles'
240.     qui gen frnt_adj_wt  = affl_wt * frnt_wt * `articles'
241.     qui gen body_adj_wt  = affl_wt * body_wt * `articles'
242.     
.     qui bys jrnl: gen first_jrnl = _n == 1
243.     qui by jrnl: gegen jrnl_N = total(id_cntr)
244.    /* qui sum impact_fctr if first_jrnl == 1
>     gen impact_shr = impact_fctr/r(sum)
>     gen reweight_N = impact_shr * `articles'
>     replace  tot_cite_N = tot_cite_N * `articles'
>     gen impact_wt = reweight_N/jrnl_N
>     gen impact_affl_wt = impact_wt * affl_wt
>     gen impact_cite_wt = reweight_N * cite_wt / tot_cite_N * `articles'
>     gen impact_cite_affl_wt = impact_cite_wt * affl_wt*/
. 
.     foreach wt in affl_wt cite_affl_wt pat_adj_wt  { //frnt_adj_wt body_adj_w
> t { // impact_affl_wt impact_cite_affl_wt 
245.         qui sum `wt'
246.         assert round(r(sum)-`articles') == 0
247.     }
248.     compress, nocoalesce
249.     save ../output/cleaned_last20yrs_`samp', replace
250. end

. 
. program clean_mesh  
  1.     syntax, samp(str) 
  2.     if "`samp'" == "top_jrnls" local fol top
  3.     if strpos("`samp'" , "all_jrnls")  > 0 local fol samp 
  4.     use ../external/`fol'/contracted_gen_mesh_`samp', clear
  5.     bys id: gen n = _n
  6.     greshape wide qualifier_name gen_mesh, i(id) j(n)
  7.     gduplicates drop id, force
  8.     save ../output/reshaped_gen_mesh_`samp', replace
  9. end

. main
(0 real changes made)

Duplicates in terms of pmid

(594 observations deleted)

Duplicates in terms of id

(0 observations are duplicates)
(1 observation deleted)
(2 observations deleted)
(0 observations deleted)
(0 observations deleted)
(1,561 observations deleted)
(113 observations deleted)
(659 observations deleted)
(49 observations deleted)
(231 observations deleted)
(149 observations deleted)
(125 observations deleted)
(111 observations deleted)
(64 observations deleted)
(547 observations deleted)
(200 observations deleted)
(331 observations deleted)
(560 observations deleted)
(0 observations deleted)
(198 observations deleted)
(96 observations deleted)
(10 observations deleted)
(1 observation deleted)
(250 observations deleted)
(707 observations deleted)
(43 observations deleted)
(0 observations deleted)
(41 observations deleted)
(54 observations deleted)
(82 observations deleted)
(206 observations deleted)
(6 observations deleted)
(132 observations deleted)
(58 observations deleted)
(6 observations deleted)
(0 observations deleted)
(39 observations deleted)
(2 observations deleted)
(74 observations deleted)
(83 observations deleted)
(44 observations deleted)
(5 observations deleted)
(713 observations deleted)
(450 observations deleted)
(115 observations deleted)
(98 observations deleted)
(279 observations deleted)
(74 observations deleted)
(588 observations deleted)
(34 observations deleted)
(25 observations deleted)
(43 observations deleted)
(648 observations deleted)
(584 observations deleted)
(479 observations deleted)
(90 observations deleted)
(659 observations deleted)
(36 observations deleted)
(1,608 observations deleted)
(42 observations deleted)
(17 observations deleted)
(12 observations deleted)
(218 observations deleted)
(2 observations deleted)
(98 observations deleted)
(209 observations deleted)
(724 observations deleted)
(204 observations deleted)
(9 observations deleted)
(99 observations deleted)
(18 observations deleted)
(2,977 observations deleted)
(166 observations deleted)
(56 observations deleted)
(578 observations deleted)
(40 observations deleted)
(9 observations deleted)
(53 observations deleted)
(15 observations deleted)
(0 observations deleted)
(51 observations deleted)
(2 observations deleted)
(0 observations deleted)
(610 observations deleted)
(8 observations deleted)
(349 observations deleted)
(450 observations deleted)
(73 observations deleted)
(106 observations deleted)
(74 observations deleted)
(9 observations deleted)
(3 observations deleted)
(29 observations deleted)
(26 observations deleted)
(12 observations deleted)
(27 observations deleted)
(52 observations deleted)
(49 observations deleted)
(52 observations deleted)
(264 observations deleted)
(9 observations deleted)
(4,533 observations deleted)
(4 observations deleted)
(1 observation deleted)
(134 observations deleted)
(290 observations deleted)
(22 observations deleted)
(207 observations deleted)
(15 observations deleted)
(18 observations deleted)
(0 observations deleted)
(222 observations deleted)
(61 observations deleted)
(0 observations deleted)
(785 observations deleted)
(0 observations deleted)
(313 observations deleted)
(2,042 observations deleted)
(22 observations deleted)
(3 observations deleted)
(1 observation deleted)
(670 observations deleted)
(731 observations deleted)
(663,880 missing values generated)
(0 observations deleted)
(136 observations deleted)
(274 observations deleted)
(0 observations deleted)
(16 observations deleted)
(0 observations deleted)
(3 observations deleted)
(36 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(27 observations deleted)
(21 observations deleted)
(24 observations deleted)
(9 observations deleted)
(7 observations deleted)
(7 observations deleted)
(8 observations deleted)
(5 observations deleted)
(4 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(3 observations deleted)
(11 observations deleted)
(19 observations deleted)
(4 observations deleted)
(16 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(13 observations deleted)
(0 observations deleted)
(0 observations deleted)
(9 observations deleted)
(27 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(3 observations deleted)
(0 observations deleted)
(0 observations deleted)
(7 observations deleted)
(3 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(0 observations deleted)
(2 observations deleted)
(5 observations deleted)
(0 observations deleted)
(0 observations deleted)
(11 observations deleted)
(209 observations deleted)
(4,068 observations deleted)
(6 observations deleted)
(9,871 observations deleted)

Duplicates in terms of lower_title jrnl
(714,776 observations deleted)

Duplicates in terms of all variables

(0 observations are duplicates)
file ../temp/possible_non_articles_top_jrnls.dta saved

    Result                      Number of obs
    -----------------------------------------
    Not matched                       714,776
        from master                   714,776  
        from using                          0  

    Matched                                 0  
    -----------------------------------------
file ../temp/openalex_top_jrnls_clean_titles.dta saved

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         5,863,763  
    -----------------------------------------

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         5,863,763  
    -----------------------------------------
(0 real changes made)
(1,465 observations deleted)
(0 real changes made)
(variable inst was str1, now str191 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                       361,366
        from master                   361,366  
        from using                          0  

    Matched                         5,500,932  
    -----------------------------------------
(5,500,932 real changes made)
(536,892 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(751 real changes made)
(0 observations deleted)
(file ../temp/cleaned_all_top_jrnls.dta not found)
file ../temp/cleaned_all_top_jrnls.dta saved
(0 real changes made)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         5,756,974  
    -----------------------------------------

Duplicates in terms of pmid athr_id inst_id

(1,548,512 observations deleted)
(file ../temp/cleaned_all_top_jrnls_prewt.dta not found)
file ../temp/cleaned_all_top_jrnls_prewt.dta saved
(157,818 real changes made)
(1,109,418 real changes made)
(3,514,389 missing values generated)
(3,514,389 missing values generated)
(3,514,389 missing values generated)
(3,514,389 missing values generated)

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
     affl_wt |  4,208,462    .1649232    .1548851        .01          1

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
cite_affl_wt |  4,208,462    .1649232    .6233803          0   613.6473

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
  pat_adj_wt |  4,208,462    .1649232    2.744544          0   1777.859
  variable pub_date was float now int
  variable pub_mnth was float now byte
  variable year was float now int
  variable qrtr was float now int
  variable num_affls was float now byte
  variable author_id was float now byte
  variable years_since_pub was float now byte
  variable id_cntr was float now byte
  variable first_jrnl was float now byte
  variable patent_count was double now long
  variable front_only was double now int
  variable body_only was double now int
  variable jrnl_N was double now long
  variable inst was str191 now str168
  variable country was str33 now str32
  variable city was str45 now str35
  (328,260,036 bytes saved)
file ../temp/pre_save.dta saved
(encoding automatically selected: ISO-8859-1)
(5 vars, 63,211 obs)
`"Alabama"' `"Alaska"' `"American Samoa"' `"Arizona"' `"Arkansas"' `"California
> "' `"Colorado"' `"Connecticut"' `"Delaware"' `"Federated States of Micronesia
> "' `"Florida"' `"Georgia"' `"Guam"' `"Hawaii"' `"Idaho"' `"Illinois"' `"India
> na"' `"Iowa"' `"Kansas"' `"Kentucky"' `"Louisiana"' `"Maine"' `"Marshall Isla
> nds"' `"Maryland"' `"Massachusetts"' `"Michigan"' `"Minnesota"' `"Mississippi
> "' `"Missouri"' `"Montana"' `"Nebraska"' `"Nevada"' `"New Hampshire"' `"New J
> ersey"' `"New Mexico"' `"New York"' `"North Carolina"' `"North Dakota"' `"Nor
> thern Mariana Islands"' `"Ohio"' `"Oklahoma"' `"Oregon"' `"Palau"' `"Pennsylv
> ania"' `"Puerto Rico"' `"Rhode Island"' `"South Carolina"' `"South Dakota"' `
> "Tennessee"' `"Texas"' `"US Armed Forces Europe"' `"US Armed Forces Pacific"'
>  `"Utah"' `"Vermont"' `"Virgin Islands"' `"Virginia"' `"Washington"' `"Washin
> gton, D.C."' `"West Virginia"' `"Wisconsin"' `"Wyoming"'
(0 real changes made)
(7,219 real changes made)
(0 real changes made)
(9 real changes made)
(0 real changes made)
(9 real changes made)
(0 real changes made)
(7 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(1 real change made)
(0 real changes made)
(46 real changes made)
(0 real changes made)
(1 real change made)
(1,489 real changes made)
(0 real changes made)
(1 real change made)
(1 real change made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(23 real changes made)
(6 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(1 real change made)
(0 real changes made)
(755 real changes made)
(3 real changes made)
(133 real changes made)
(0 real changes made)
(5 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(8 real changes made)
(0 real changes made)
(3 real changes made)
(0 real changes made)
(0 real changes made)
(1 real change made)
(7 real changes made)
(0 real changes made)
(0 real changes made)
(8 real changes made)
(0 real changes made)
(0 real changes made)
(14 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(38 real changes made)
(2,581 real changes made)
(172 real changes made)
(14 real changes made)
(340 real changes made)
(197 real changes made)
(7 real changes made)
(166 real changes made)
(100 real changes made)
(1,221 real changes made)
(4 real changes made)
(111 real changes made)
(0 real changes made)
(0 real changes made)
(554 real changes made)
(0 real changes made)
(22 real changes made)
(49 real changes made)
(9,168 real changes made)
(8,611 real changes made)
(1,685 real changes made)
(0 real changes made)
(18 real changes made)
(12 real changes made)
(98 real changes made)
(51 real changes made)
(4,036 real changes made)
(170 real changes made)
(1 real change made)
(0 real changes made)
(1,819 real changes made)
(458 real changes made)
(324 real changes made)
(111 real changes made)
(0 real changes made)
(50 real changes made)
(174 real changes made)
(19 real changes made)
(3 real changes made)
(404 real changes made)
(0 real changes made)
(3 real changes made)
(0 real changes made)
(96 real changes made)
(11 real changes made)
(16 real changes made)
(2,349 real changes made)
(360 real changes made)
(0 real changes made)
(8 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(195 real changes made)
(202 real changes made)
file ../temp/fill_msa.dta saved
(encoding automatically selected: ISO-8859-1)
(5 vars, 63,211 obs)
(1 observation deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                     2,672,727
        from master                         0  
        from using                  2,672,727  

    Matched                         1,535,735  
    -----------------------------------------
(51 real changes made)
(0 real changes made)
(29,944 real changes made)
(0 real changes made)
(0 real changes made)
(variable msatitle was str46, now str50 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                     2,692,511
        from master                 2,692,511  
        from using                          0  

    Matched                         1,515,951  
    -----------------------------------------
(51 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(51 real changes made)
(0 real changes made)
(0 real changes made)
(51 real changes made)
(51 real changes made)
(0 real changes made)
(file ../output/cleaned_top_jrnls.dta not found)
file ../output/cleaned_top_jrnls.dta saved
(file ../temp/pmid_id_xwalk_top_jrnls.dta not found)
file ../temp/pmid_id_xwalk_top_jrnls.dta saved
(1,130,582 observations deleted)
(2,691,285 missing values generated)
(2,691,285 missing values generated)
(2,691,285 missing values generated)
(2,691,285 missing values generated)
N = 3,077,880; 386,595 unbalanced groups of sizes 1 to 100
  variable patent_count was long now int
  variable first_jrnl was float now byte
  variable population was double now long
  variable jrnl_N was double now long
  variable region was str30 now str28
  variable doi was str55 now str54
  variable msatitle was str50 now str46
  (61,557,600 bytes saved)
(file ../output/cleaned_last20yrs_top_jrnls.dta not found)
file ../output/cleaned_last20yrs_top_jrnls.dta saved
file ../external/top/contracted_gen_mesh_top_jrnls.dta not found
r(601);

end of do-file

r(601);


. [?1l>